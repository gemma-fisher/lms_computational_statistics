## MRC LMS - Introduction to computational statistics

### Jes√∫s Urtasun Elizari, MRC LMS & RCDS ICL

LMS email address `Jesus.Urtasun@lms.mrc.ac.uk`

ICL email address `jurtasun@ic.ac.uk`

<img src="/readme_figures/ukri_lms_logo.png" width = 700>

### Find the content of the course in GitHub:
[LMS Introduction to computational statistics](https://github.com/LMSBioinformatics/lms_computational_statistics)

This course provides an introduction to computational statistics. 
The aim of the course is to build simple and accessible yet strong mathematical foundations in probability theory, descriptive statistics, 
and hypothesis testing, while learning how to interpret and analyze data with clarity and confidence.

In each chapter, we will navigate together through practical exercises that connect theory to real-world applications, using `Python` and `R` with real datasets. 

No prior mathematical or programming experience is required to attend this course.
The course is organized in four chapters, covering the topics listed below. 

## Roadmap of the course

### Chapter 1. Prediction and inference.

- General frameworks for statistics and probability.
- Introduction to descriptive statistics, population and sampling.
- Statistical estimators for central tendency and variation.
- Data visualization: histogram, box, violin, dispersion.

### Chapter 2. Foundations of probability.

- Introduction to probability and random events.
- Discrete events: Bernoulli, Binomial, Poisson, and discrete Uniform distributions.
- Continuous events: Gaussian, Exponential, and continous Uniform distributions.
- Mean and variance as expected values.

### Chapter 3. Hypothesis testing (I): Parameter estimation.

- Prediction vs inference revisited. Variables, parameters and estimators.
- The Law of Large Numbers (LLN).
- The Central Limit Theorem (CLT).
- Confidence intervals and critical regions.

### Chapter 4. Hypothesis testing (II): Some examples.

- The modern Pearson-Neyman approach to hypothesis testing.
- Common examples of statistical tests (t-test, Fisher exact, ANOVA, &chi;<sup>2</sup>).
- Parametric vs non-parametric tests.
- Revisiting P-values: errors, power, and Bayesian probability.

### Chapter 5. Introduction to Bayesian probability.

- Error types in hypothesis testing. The Fisher and the Pearson-Neyman approach.
- Independent and conditional events.
- Conditional probability: The Bayes rule.

## Setting up your `codespace`

Navigate to the green `code` tab, then press the `codespaces` tab and `create a codespace on main`:

<img src="/readme_figures/codespaces1.png" width="800">

Press the `codespaces` tab in the upper-right corner:

<img src="/readme_figures/codespaces2.png" width="500">

Once logged-in, press the `codespaces` tab and `create a codespace on main`

<img src="/readme_figures/codespaces3.png" width="500">

## Remote acces to `JEX`

Open a terminal and type
```
ssh user@jex.lms.mrc.ac.uk
```

## Remote acces to `Imperial HPC`

Open a terminal and type
```
ssh user@login.hpc.ic.ac.uk
```

## Setting up `Python` and `R` on your own machine
Setting up `Python` and `R` on your own machine

### Instructions for Mac and Linux
Instructions for Mac and Linux (...)

### Instructions for Windows
Instructions for Windows (...)

## Licence
This work is licensed under a [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Licence](http://creativecommons.org/licenses/by-nc-sa/4.0/).
